{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"LangTorch: The LLM package that writes itself","text":""},{"location":"#why-choose-langtorch","title":"Why Choose LangTorch?","text":"<p>LangTorch is a framework that simplifies complex LLM application development by leveraging familiar PyTorch concepts.</p> <p>While existing frameworks focus on wrappers for connecting language models to other services, LangTorch aims to change the way you approach building LLM applications by introducing a unified framework centered around text tensors and modules. The result? Faster, more efficient, and intricate LLM application development.</p>"},{"location":"#the-langtorch-framework","title":"The LangTorch Framework","text":"<p>The proposed framework is so intuitive that LLMs can write LangTorch code on their own from only a short description. In effect LangTorch lets LLMs program themselves, which opens a completely new realm for agentic LLM applications. To achieve this design, core LangTorch components subclass their PyTorch counterparts, which also empowers developers to apply their existing skills to building novel LLM app architectures.</p> <ul> <li> <p>TextTensors unify prompt templates, completion dictionaries, chat histories and indexes under a single, powerful data structure. Inheriting functionalities from <code>torch.Tensor</code>, TextTensors hold arrays of structured Text data. </p> </li> <li> <p>TextModules are the compositional building blocks. A subclass of <code>torch.nn.Module</code>, TextModules can perform all operations you may need in an LLM chain and more. </p> </li> </ul>"},{"location":"#what-makes-langtorch-unique","title":"What Makes LangTorch Unique?","text":"<p>Instead of magical methods to memorize, LangTorch defines simple rules for <code>TextTensor</code> operations like addition and multiplication, enabling all kinds of text formatting and transformations. This lets developers think about what they want to build, instead of how the classes were named. </p> <pre><code>template = TextTensor([[\"Explain {theory} in terms of {framework}\"],  \n                       [\"Argue how {framework} can prove {theory}\"]])  \n\nresult = template * TextTensor({\"theory\": \"active inference\", \"framework\": \"thermodynamics\" })\n\nprint(result)\n# Outputs: [[Explain active inference in terms of thermodynamics]\n#           [Argue how thermodynamics can prove active inference]]\n</code></pre> <p>As <code>TextModules</code> operate on tensor data, all operations are easily parallelizable and integrate seamlessly with PyTorch, Transformers Models and APIs. Chaining TextModules offers both low-level control and a higher level of architectural abstraction.</p> <ul> <li>LangTorch's intuitive architecture allows for smooth transitioning from conventional AI development, making prompt engineering, templating and LLM calls all work with torch constructs like <code>nn.Sequential</code>:</li> </ul> <pre><code>chain = torch.nn.Sequential(\n    TextModule(\"Calculate this equation:\\n\"),\n    langtorch.methods.CoT,\n    GPT4()\n    TextModule(\"Is this reasoning correct?\\n\")\n    GPT4(T=0.)\n)\n\noutput = chain(TextTensor([\"170*32 =\", \"8**3*2000 =\", \"123*45/10 =\", \"2**10*5 =\"]))\nprint(output.shape) # Outputs: (4,)\n</code></pre> <ul> <li> <p>Deep Integration: Each retriever, chain, chat or agent, can be implemented in LangTorch using PyTorch design patterns, such as classes with a forward method, that integrate both tensor data (e.g. embeddings) and textual data (e.g. prompt templates).</p> </li> <li> <p>Flexible and Scalable: From simple tasks to complex LLM chains, LangTorch scales seamlessly, accommodating both beginners and expert developers.</p> </li> </ul>"},{"location":"#dive-in-and-get-started","title":"Dive In and Get Started","text":"<p>Install LangTorch with: <pre><code>pip install langtorch\n</code></pre></p> <p>Whether you're just starting out or are an experienced developer, LangTorch has tools and functionalities to meet your needs. Our documentation provides a Quick-Start Tutorial to help you craft your first application swiftly. Once you're familiar with the basics, delve deeper with Conceptual guides and our Documentation Reference. </p> <p>For hands-on examples, visit End-to-End Tutorials or compare End-to-End implementations in LangTorch vs LangChain Examples.</p> <p>Join us in revolutionizing the future of LLM application development. Welcome to the LangTorch era.</p>"},{"location":"quickstart/","title":"Quickstart Guide: Dive into LangTorch","text":"<p>Welcome to LangTorch, where building Language and Linguistic Model (LLM) applications is as intuitive as crafting a PyTorch model. This Quickstart Guide is designed to set you on the path of creating powerful LLM applications efficiently.</p>"},{"location":"quickstart/#pre-requisites","title":"Pre-requisites","text":"<ul> <li>Python 3.8 or higher</li> <li>PyTorch 2.0.0 or higher</li> </ul>"},{"location":"quickstart/#installation","title":"Installation","text":"<p>Install LangTorch using pip:</p> <pre><code>pip install langtorch\n</code></pre>"},{"location":"quickstart/#the-langtorch-building-blocks","title":"The LangTorch Building Blocks","text":""},{"location":"quickstart/#texttensors-the-powerhouse-of-text","title":"TextTensors: The Powerhouse of Text","text":"<p>TextTensors in LangTorch are designed to simplify the handling of textual data. They inherit from PyTorch's <code>torch.Tensor</code> but are specialized to hold textual data. </p>"},{"location":"quickstart/#creating-a-texttensor","title":"Creating a TextTensor","text":"<pre><code>from langtorch import TextTensor\n\n# Initialize with a list of strings\ntt = TextTensor([[\"Hello, world!\"], [\"How are you?\"]])\n</code></pre>"},{"location":"quickstart/#texttensor-operations","title":"TextTensor Operations","text":"<p>Addition concatenates the text, while multiplication performs template formatting:</p> <pre><code># Concatenation\nnew_tt = tt + \" Have a great day!\"\n\n# Template formatting\nformatted_tt = TextTensor([\"{greeting}, {name}!\"]) * TextTensor({\"greeting\": \"Hello\", \"name\": \"Alice\"})\n</code></pre>"},{"location":"quickstart/#text-keys","title":"Text Keys","text":"<p>You can explicitly assign or change keys in a TextTensor using the <code>set_key()</code> method:</p> <pre><code># Assign new keys\ntt_new_keys = tt.set_key(\"new_key\")\n</code></pre>"},{"location":"quickstart/#text-the-atomic-unit-of-texttensor","title":"Text: The Atomic Unit of TextTensor","text":"<p>LangTorch introduces a <code>Text</code> class that acts like an ordered dictionary but with the functionality of a string. You can initialize it with key-value pairs and perform operations like regular strings.</p> <pre><code>from langtorch import Text\n\n# Create a Text object\ntext_obj = Text((\"greeting\", \"Hello\"), (\"object\", \"world\"))\n</code></pre> <p>You can use the <code>Text</code> class to create complex TextTensors, and then apply the <code>set_key()</code> function to change keys if needed.</p>"},{"location":"quickstart/#textmodules-the-operators","title":"TextModules: The Operators","text":"<p>TextModules are akin to PyTorch's <code>nn.Module</code> but are customized to operate on TextTensors. They multiply the input TextTensor with internal content and pass it to an \"activation function,\" which in this context is an LLM call.</p> <pre><code>from langtorch import TextModule, ChatGPT\n\nllm = ChatGPT(\"gpt4\")\n# Initialize a TextModule\ntext_mod = TextModule(\"Translate this text: {}\", activation=llm)\n</code></pre>"},{"location":"quickstart/#chaining-textmodules","title":"Chaining TextModules","text":"<p>LangTorch enables you to create complex pipelines, similar to how you'd use <code>nn.Sequential</code> in PyTorch.</p> <pre><code>import torch\n\n# Create a pipeline\npipeline = torch.nn.Sequential(\n    TextModule(\"Translate this text: {}\"),\n    TextModule(\"Summarize the translated text: {}\", activation=SomeSummarizationLLM)\n)\n</code></pre>"},{"location":"quickstart/#running-your-pipeline","title":"Running Your Pipeline","text":"<p>Execute the pipeline by simply passing your TextTensor:</p> <pre><code>output = pipeline(tt)\n</code></pre>"},{"location":"quickstart/#advanced-tips","title":"Advanced Tips","text":"<ul> <li>Cosine Similarities: LangTorch provides a <code>CosineSimilarity</code> class to compute similarities between TextTensors.</li> </ul> <pre><code>from langtorch.tt import CosineSimilarity\n\ncos = CosineSimilarity()\nsimilarities = cos(tt, TextTensor([\"1\", \"0\", \"No\", \"Yes\"]))\n</code></pre> <ul> <li> <p>Temperature Settings: For creative tasks, set a high temperature (e.g., 1.2), and for more analytical tasks, a lower temperature (e.g., 0.5).</p> </li> <li> <p>Key Management: Always make sure the TextTensors have the correct keys that the TextModule templates expect. Utilize the <code>set_key()</code> method and the <code>key</code> argument in <code>TextModule</code> for this.</p> </li> </ul>"},{"location":"quickstart/#next-steps","title":"Next Steps","text":"<p>Congratulations, you've completed the Quickstart Guide! For a deeper understanding, explore our Conceptual Guides and API Documentation.</p> <p>Feel free to contribute; check our contribution guidelines.</p> <p>Happy LangTorching! \ud83c\udf89</p>"},{"location":"guides/text/","title":"1. Text Multiplication Guide","text":""},{"location":"guides/text/#what-is-a-text","title":"What is a Text?","text":"<p>The basic object in LangTorch is <code>langtorch.TextTensor</code>, corresponding to <code>torch.nn.Tensor</code>. While <code>nn.Tensor</code> is a tensor of numbers, the <code>TextTensor</code> is a tensor of <code>Text</code> objects. Text objects are not simply strings to allow them to represent more complex objects and undergo more complex operations (e.g. multiplication, which will be a composition operation for Text objects that acts similar to the string .format method).  which are defined by a tuple <code>(content, key)</code> where content and key are regular strings.</p>"},{"location":"guides/text/#1-basics","title":"1. Basics:","text":""},{"location":"guides/text/#text","title":"Text:","text":"<ul> <li>Represents a sequence of \"named strings\". It acts as a regular string instance, but provides additional methods to manipulate the named strings within.</li> <li>The class provides multiple ways of creating instances, either through direct invocation or using patterns. That will be in the next chapter.</li> <li>The <code>Text</code> class can be initialised in multiple ways. This section focuses on constructing Text from strings, lists and dictionaries. A more convenient way is to use a sepcial f-string-like sytnax which can parse most Text\u2019s from a signle string. This is explained in the next chapter.</li> </ul> <pre><code># Creating a Text object with (key,  value) syntax:\ntext_obj = Text((\"greeting\", \"Hello\"), (\"object\", \"world\"))\nprompt = TextTensor([\"{object} says: {greating}\"}])\nprint(text_obj)  # Outputs: Helloworld\nprint(prompt*text_obj)  # Outputs: world says: Hello\n\n# Tho get substrings of the Text, the content attribute holds sub-Texts:\nprint(text_obj.content)  # Outputs: [Text((\"greeting\", \"Hello\")), Text((\"object\", \"world\"))]\n\n# Accessing the items (key-value pairs) of a Text object:\nitems = text_obj.items()\nprint(items)  # Outputs: [(\"greeting\", \"Hello\"), (\"object\", \"world\")]\n</code></pre>"},{"location":"guides/text/#2-operations-on-text","title":"2. Operations on Text:","text":""},{"location":"guides/text/#addition-operation","title":"Addition Operation:","text":"<p>The addition operation on <code>Text</code> and <code>TextTensors</code> simply concatenates them.</p> <pre><code># Concatenating two Text objects:\ntext1 = Text((\"greeting\", \"Hello\"))\ntext2 = Text((\"object\", \"world\"), \"!\")\nresult_text = text1 + text2\nprint(result_text)  # Outputs: Helloworld!\n\n# Mixing str2 and Text:\nmix_result = str1 + text2\nprint(mix_result)  # Outputs: Helloworld!\n</code></pre>"},{"location":"guides/text/#multiplication-operation","title":"Multiplication Operation:","text":"<p>The heart of this system is the multiplication operation, defined in the <code>__mul__</code> method of both classes. Here's how it works:</p>"},{"location":"guides/text/#single-key-text-multiplication","title":"Single-key Text Multiplication:","text":"<ul> <li> <p><code>str2 * str2</code>: When two Text objects are multiplied:</p> <ul> <li>If their keys match but not their contents, the contents get concatenated.</li> <li>If one is the inverse of the other (content and key swapped), the identity (an empty string) is returned.</li> <li> <p>If the content of the first <code>str2</code> matches the key of the second it acts as a format operation. For example:</p> <pre><code> Text((\"\",\"key\")) * Text(\"key\",\"value\") == Text((\"\", \"value\"))\n</code></pre> <p>You can interpret the whole operation like a multiplication of rational numbers:</p> <p>$$</p> <p>\\frac{\\text{'It works'}}{\\text{'a key'}}\\circ\\frac{\\text{ ' like this'}}{\\text{'a key'}} = \\frac{\\text{'It works like this'}}{\\text{'a key'}}\\ \\text{and}\\</p> <p>\\frac{\\text{'a phrase'}}{\\text{''}}\\circ\\frac{\\text{ 'text'}}{\\text{'a phrase'}} = \\frac{\\text{'text'}}{\\text{''}} $$</p> </li> <li> <p>For different keys, a new <code>Text</code> object is created with one <code>str2</code> instance after the other.</p> </li> <li><code>str2 * str</code>: If a <code>str2</code> object is multiplied with a regular string:</li> <li>If the <code>str2</code> doesn't have a key, the regular string is simply concatenated to its content.</li> <li>Otherwise, a new <code>Text</code> object is created with the <code>str2</code> followed by the regular string.</li> </ul> </li> </ul>"},{"location":"guides/text/#longer-text-multiplication","title":"Longer Text Multiplication:","text":"<ul> <li><code>Text * str2</code>: The str2 goes from left to right and if it finds a match for any of the rules above it applies it to that substring of Text, if none such match is found it appends itself to the Text</li> <li><code>Text * Text</code>: similar but for every in the right Text, it becomes clearer when we introduce creating Texts from strings</li> </ul>"},{"location":"guides/text/#inverse-operation","title":"Inverse Operation:","text":"<p>The inverse of a Text is obtained by swapping the key and content. To get the inverse of a Text you can either use the <code>inv()</code> method or the power operation <code>**-1</code>. The Text multiplied by its inverse is the empty string (<code>Text.identity</code>), as shown below.</p> <pre><code># For Text:\ntext_obj = Text((\"Hello\", \"greeting\"), (\"world\", \"object\"))\n# text_obj.inv() == text_obj**-1 == Text((\"greeting\", \"Hello\"), \n#                                                                                (\"object\", \"world\"))\n\n# We have:\n# text_obj*(text_obj**-1) == Text.identity == \"\"\n</code></pre>"},{"location":"guides/text/#4-additional-points","title":"4. Additional Points:","text":"<ul> <li> <p>The <code>Text</code> class has a a special value <code>Text.identity</code>: an empty string with no key. This value is characterised by being it being the identity element of multiplication and  <code>Text.identity == 1</code> is defined to be true to make that connection, as:</p> <pre><code>some_text * 1 == some_text * Text.identity\n</code></pre> </li> </ul>"},{"location":"reference/t/","title":"1. Text Multiplication Guide","text":""},{"location":"reference/t/#what-is-a-text","title":"What is a Text?","text":"<p>The basic object in LangTorch is <code>langtorch.TextTensor</code>, corresponding to <code>torch.nn.Tensor</code>. While <code>nn.Tensor</code> is a tensor of numbers, the <code>TextTensor</code> is a tensor of <code>Text</code> objects. Text objects are not simply strings to allow them to represent more complex objects and undergo more complex operations (e.g. multiplication, which will be a composition operation for Text objects that acts similar to the string .format method).  which are defined by a tuple <code>(content, key)</code> where content and key are regular strings.</p>"},{"location":"reference/t/#1-basics","title":"1. Basics:","text":""},{"location":"reference/t/#text","title":"Text:","text":"<ul> <li>Represents a sequence of \"named strings\". It acts as a regular string instance, but provides additional methods to manipulate the named strings within.</li> <li>The class provides multiple ways of creating instances, either through direct invocation or using patterns. That will be in the next chapter.</li> <li>The <code>Text</code> class can be initialised in multiple ways. This section focuses on constructing Text from strings, lists and dictionaries. A more convenient way is to use a sepcial f-string-like sytnax which can parse most Text\u2019s from a signle string. This is explained in the next chapter.</li> </ul> <pre><code># Creating a Text object with (key,  value) syntax:\ntext_obj = Text((\"greeting\", \"Hello\"), (\"object\", \"world\"))\nprompt = TextTensor([\"{object} says: {greating}\"}])\nprint(text_obj)  # Outputs: Helloworld\nprint(prompt*text_obj)  # Outputs: world says: Hello\n\n# Tho get substrings of the Text, the content attribute holds sub-Texts:\nprint(text_obj.content)  # Outputs: [Text((\"greeting\", \"Hello\")), Text((\"object\", \"world\"))]\n\n# Accessing the items (key-value pairs) of a Text object:\nitems = text_obj.items()\nprint(items)  # Outputs: [(\"greeting\", \"Hello\"), (\"object\", \"world\")]\n</code></pre>"},{"location":"reference/t/#2-operations-on-text","title":"2. Operations on Text:","text":""},{"location":"reference/t/#addition-operation","title":"Addition Operation:","text":"<p>The addition operation on <code>Text</code> and <code>TextTensors</code> simply concatenates them.</p> <pre><code># Concatenating two Text objects:\ntext1 = Text((\"greeting\", \"Hello\"))\ntext2 = Text((\"object\", \"world\"), \"!\")\nresult_text = text1 + text2\nprint(result_text)  # Outputs: Helloworld!\n\n# Mixing str2 and Text:\nmix_result = str1 + text2\nprint(mix_result)  # Outputs: Helloworld!\n</code></pre>"},{"location":"reference/t/#multiplication-operation","title":"Multiplication Operation:","text":"<p>The heart of this system is the multiplication operation, defined in the <code>__mul__</code> method of both classes. Here's how it works:</p>"},{"location":"reference/t/#single-key-text-multiplication","title":"Single-key Text Multiplication:","text":"<ul> <li> <p><code>str2 * str2</code>: When two Text objects are multiplied:</p> <ul> <li>If their keys match but not their contents, the contents get concatenated.</li> <li>If one is the inverse of the other (content and key swapped), the identity (an empty string) is returned.</li> <li> <p>If the content of the first <code>str2</code> matches the key of the second it acts as a format operation. For example:</p> <pre><code> Text((\"\",\"key\")) * Text(\"key\",\"value\") == Text((\"\", \"value\"))\n</code></pre> <p>You can interpret the whole operation like a multiplication of rational numbers:</p> <p>$$</p> <p>\\frac{\\text{'It works'}}{\\text{'a key'}}\\circ\\frac{\\text{ ' like this'}}{\\text{'a key'}} = \\frac{\\text{'It works like this'}}{\\text{'a key'}}\\ \\text{and}\\</p> <p>\\frac{\\text{'a phrase'}}{\\text{''}}\\circ\\frac{\\text{ 'text'}}{\\text{'a phrase'}} = \\frac{\\text{'text'}}{\\text{''}} $$</p> </li> <li> <p>For different keys, a new <code>Text</code> object is created with one <code>str2</code> instance after the other.</p> </li> <li><code>str2 * str</code>: If a <code>str2</code> object is multiplied with a regular string:</li> <li>If the <code>str2</code> doesn't have a key, the regular string is simply concatenated to its content.</li> <li>Otherwise, a new <code>Text</code> object is created with the <code>str2</code> followed by the regular string.</li> </ul> </li> </ul>"},{"location":"reference/t/#longer-text-multiplication","title":"Longer Text Multiplication:","text":"<ul> <li><code>Text * str2</code>: The str2 goes from left to right and if it finds a match for any of the rules above it applies it to that substring of Text, if none such match is found it appends itself to the Text</li> <li><code>Text * Text</code>: similar but for every in the right Text, it becomes clearer when we introduce creating Texts from strings</li> </ul>"},{"location":"reference/t/#inverse-operation","title":"Inverse Operation:","text":"<p>The inverse of a Text is obtained by swapping the key and content. To get the inverse of a Text you can either use the <code>inv()</code> method or the power operation <code>**-1</code>. The Text multiplied by its inverse is the empty string (<code>Text.identity</code>), as shown below.</p> <pre><code># For Text:\ntext_obj = Text((\"Hello\", \"greeting\"), (\"world\", \"object\"))\n# text_obj.inv() == text_obj**-1 == Text((\"greeting\", \"Hello\"), \n#                                                                                (\"object\", \"world\"))\n\n# We have:\n# text_obj*(text_obj**-1) == Text.identity == \"\"\n</code></pre>"},{"location":"reference/t/#4-additional-points","title":"4. Additional Points:","text":"<ul> <li> <p>The <code>Text</code> class has a a special value <code>Text.identity</code>: an empty string with no key. This value is characterised by being it being the identity element of multiplication and  <code>Text.identity == 1</code> is defined to be true to make that connection, as:</p> <pre><code>some_text * 1 == some_text * Text.identity\n</code></pre> </li> </ul>"}]}