
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="..">
      
      
        <link rel="next" href="../reference/">
      
      
      <link rel="icon" href="../langtorch_fav.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.9">
    
    
      
        <title>Quickstart tutorial - LangTorch Docs</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.f2e4d321.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css">
    
      <link rel="stylesheet" href="../css/custom.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#quickstart-guide-dive-into-langtorch" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="LangTorch Docs" class="md-header__button md-logo" aria-label="LangTorch Docs" data-md-component="logo">
      
  <img src="../langtorch_banner.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            LangTorch Docs
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Quickstart tutorial
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="LangTorch Docs" class="md-nav__button md-logo" aria-label="LangTorch Docs" data-md-component="logo">
      
  <img src="../langtorch_banner.png" alt="logo">

    </a>
    LangTorch Docs
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Quickstart tutorial
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Quickstart tutorial
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#installation" class="md-nav__link">
    <span class="md-ellipsis">
      Installation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-simple-chains" class="md-nav__link">
    <span class="md-ellipsis">
      1. Simple chains
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. Simple chains">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#getting-tensor-text-data" class="md-nav__link">
    <span class="md-ellipsis">
      Getting tensor text data
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#texttensor-operations-for-prompt-templating" class="md-nav__link">
    <span class="md-ellipsis">
      TextTensor operations for prompt templating
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#performing-a-task-with-textmodules" class="md-nav__link">
    <span class="md-ellipsis">
      Performing a task with TextModules
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-implementing-popular-methods" class="md-nav__link">
    <span class="md-ellipsis">
      2. Implementing popular methods
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. Implementing popular methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parallel-and-chained-calls-with-textmodules" class="md-nav__link">
    <span class="md-ellipsis">
      Parallel and Chained calls with TextModules
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#chain-of-thought" class="md-nav__link">
    <span class="md-ellipsis">
      Chain of Thought
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ensemble-self-consistency" class="md-nav__link">
    <span class="md-ellipsis">
      Ensemble / Self-consistency
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#working-with-structured-documents" class="md-nav__link">
    <span class="md-ellipsis">
      Working with structured documents
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-using-tensor-embeddings-to-build-retrievers" class="md-nav__link">
    <span class="md-ellipsis">
      3. Using Tensor Embeddings to Build Retrievers
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Using Tensor Embeddings to Build Retrievers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#build-custom-retriever-and-rag-modules" class="md-nav__link">
    <span class="md-ellipsis">
      Build Custom Retriever and RAG modules
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../reference/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Reference
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3" id="__nav_3_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../reference/langtorch/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    langtorch
  </span>
  

            </a>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            langtorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../reference/text/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    langtorch.Text
  </span>
  

            </a>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3">
            <span class="md-nav__icon md-icon"></span>
            langtorch.Text
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../reference/parsing/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Text Parsing and Chats
  </span>
  

            </a>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4">
            <span class="md-nav__icon md-icon"></span>
            Text Parsing and Chats
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../reference/texttensor/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    langtorch.TextTensor
  </span>
  

            </a>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_5">
            <span class="md-nav__icon md-icon"></span>
            langtorch.TextTensor
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_6" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../reference/tensorattrs/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    TextTensor Attributes
  </span>
  

            </a>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_6">
            <span class="md-nav__icon md-icon"></span>
            TextTensor Attributes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_7" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../reference/multiplication/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    TextTensor Multiplication
  </span>
  

            </a>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_7">
            <span class="md-nav__icon md-icon"></span>
            TextTensor Multiplication
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_8" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../reference/tt/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    langtorch.tt
  </span>
  

            </a>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_8">
            <span class="md-nav__icon md-icon"></span>
            langtorch.tt
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_9" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../reference/textmodule/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    langtorch.tt.TextModule
  </span>
  

            </a>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_9">
            <span class="md-nav__icon md-icon"></span>
            langtorch.tt.TextModule
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_10" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../reference/activation/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    langtorch.tt.Activation
  </span>
  

            </a>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_10">
            <span class="md-nav__icon md-icon"></span>
            langtorch.tt.Activation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#installation" class="md-nav__link">
    <span class="md-ellipsis">
      Installation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-simple-chains" class="md-nav__link">
    <span class="md-ellipsis">
      1. Simple chains
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. Simple chains">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#getting-tensor-text-data" class="md-nav__link">
    <span class="md-ellipsis">
      Getting tensor text data
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#texttensor-operations-for-prompt-templating" class="md-nav__link">
    <span class="md-ellipsis">
      TextTensor operations for prompt templating
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#performing-a-task-with-textmodules" class="md-nav__link">
    <span class="md-ellipsis">
      Performing a task with TextModules
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-implementing-popular-methods" class="md-nav__link">
    <span class="md-ellipsis">
      2. Implementing popular methods
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. Implementing popular methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parallel-and-chained-calls-with-textmodules" class="md-nav__link">
    <span class="md-ellipsis">
      Parallel and Chained calls with TextModules
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#chain-of-thought" class="md-nav__link">
    <span class="md-ellipsis">
      Chain of Thought
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ensemble-self-consistency" class="md-nav__link">
    <span class="md-ellipsis">
      Ensemble / Self-consistency
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#working-with-structured-documents" class="md-nav__link">
    <span class="md-ellipsis">
      Working with structured documents
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-using-tensor-embeddings-to-build-retrievers" class="md-nav__link">
    <span class="md-ellipsis">
      3. Using Tensor Embeddings to Build Retrievers
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Using Tensor Embeddings to Build Retrievers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#build-custom-retriever-and-rag-modules" class="md-nav__link">
    <span class="md-ellipsis">
      Build Custom Retriever and RAG modules
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="quickstart-guide-dive-into-langtorch">Quickstart Guide: Dive into LangTorch</h1>
<h3 id="installation">Installation</h3>
<p>LangTorch works with Python 3.8 or higher. To install LangTorch using pip:</p>
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>langtorch
</code></pre></div>
<h2 id="1-simple-chains">1. Simple chains</h2>
<h3 id="getting-tensor-text-data">Getting tensor text data</h3>
<p><code>TextTensors</code> are designed to simplify simultaneous handling of text data. They inherit most functionality from PyTorch's <code>torch.Tensor</code> but hold textual data, which you may create from documents, prompt templates, completion dictionaries and more.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">langtorch</span> <span class="kn">import</span> <span class="n">TextTensor</span>

<span class="n">tt</span> <span class="o">=</span> <span class="n">TextTensor</span><span class="p">([[</span><span class="s2">&quot;prompt1&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;prompt2&quot;</span><span class="p">]])</span>

<span class="n">lines</span> <span class="o">=</span> <span class="n">TextTensor</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s1">&#39;doc.txt&#39;</span><span class="p">,</span><span class="s1">&#39;r&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">readlines</span><span class="p">())</span>

<span class="c1"># Append to every entry in lines</span>
<span class="n">lines</span> <span class="o">=</span> <span class="n">lines</span> <span class="o">+</span> <span class="s2">&quot; Have a great day!&quot;</span>
</code></pre></div>
<h3 id="texttensor-operations-for-prompt-templating">TextTensor operations for prompt templating</h3>
<p><code>TextTensors</code> provide operations that allow for formatting and editing many entries at the same time according to array broadcasting rules. Adding a <code>TextTensors</code> appends its content to the other, while multiplication performs a more complex operation that can be used for template formatting:</p>
<div class="highlight"><pre><span></span><code><span class="n">completions</span> <span class="o">=</span> <span class="n">TextTensor</span><span class="p">([[{</span><span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;Luciano&quot;</span><span class="p">}],</span>
                          <span class="p">[{</span><span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;Massimo&quot;</span><span class="p">}]])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">completions</span><span class="p">)</span>
<span class="c1"># Output</span>


<span class="c1"># Prompt template formatting</span>
<span class="n">prompts</span> <span class="o">=</span> <span class="n">TextTensor</span><span class="p">([</span><span class="s2">&quot;Hello, </span><span class="si">{name}</span><span class="s2">!&quot;</span><span class="p">])</span> <span class="o">*</span> <span class="n">completions</span>
</code></pre></div>
<p>A useful informal definition for the multiplication operation is that when two entries are multiplied, the right Text acts like a format operation: replacing keys with values (here, {name} with Luciano) or appending if there is nothing to replace. For a more in depth look, see <a href="../reference/multiplication">TextTensor Multiplication</a>.</p>
<h3 id="performing-a-task-with-textmodules">Performing a task with TextModules</h3>
<p>TextModules like <code>nn.Module</code> implement a forward method that works on (text) tensors. By default, they can be initialized by passing a TextTensor of prompts, that in the forward pass will be formatted using the input TextTensor (just like in the example above).  </p>
<p>To achieve interesting behavior, an nn.Module layer usually ends with passing the multiplied tensors to an "activation function". By analogy, TextModules usually end with an activation of an LLM call on the formatted prompts (for more on this parallel see. <a href="../reference/tt">langtorch.tt</a>). LangTorch activation like <code>OpenAI</code> execute their LLM calls on each entry of the input TextTensor in parallel.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">langtorch</span> <span class="kn">import</span> <span class="n">TextModule</span><span class="p">,</span> <span class="n">OpenAI</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">,</span> <span class="n">T</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">)</span> <span class="c1"># Pass any API kwargs here to customize the call </span>
<span class="c1"># Initialize TextModule with the activation</span>
<span class="n">translate</span> <span class="o">=</span> <span class="n">TextModule</span><span class="p">(</span><span class="s2">&quot;Translate this text to Polish: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">llm</span><span class="p">)</span>

<span class="c1"># We can run our task on any TextTensor input</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">translate</span><span class="p">(</span><span class="n">prompts</span><span class="p">)</span>
</code></pre></div>
<p>Remember to set your API key e.g. with:</p>
<div class="highlight"><pre><span></span><code><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;OPENAI_API_KEY&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">key</span>
</code></pre></div>
<h2 id="2-implementing-popular-methods">2. Implementing popular methods</h2>
<h3 id="parallel-and-chained-calls-with-textmodules">Parallel and Chained calls with TextModules</h3>
<p>LangTorch uses a custom implementation to speed up and cache api calls, that by default run in parallel for all TextTensor entries passed to an LLM activation. As such, running calls in parallel is done automatically if either multiple prompts, multiple input values or both are passed to an LLM. </p>
<p>The simplest way to chain TextModule is to directly use <code>torch.nn.Sequential</code>. To create any complex chain you may, as in torch, define a module subclass that adds custom behavior or combines many submodules in one.  We will show these on examples of popular LLM methods.</p>
<h3 id="chain-of-thought">Chain of Thought</h3>
<p>The simplest example of a custom module are those that implement prompting methods like Chain of Thought, where all we need is to append a fixed string to the input. This can be done by creating a reusable TextModule that we can chain with any task module:  </p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">langtorch</span> <span class="kn">import</span> <span class="n">TextModule</span><span class="p">,</span> <span class="n">OpenAI</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># Remember to add spaces or new line characters to the appended texts</span>
<span class="n">chain_of_thought</span> <span class="o">=</span> <span class="n">TextModule</span><span class="p">(</span><span class="s2">&quot; Let&#39;s think step by step.&quot;</span><span class="p">)</span>  
<span class="n">task</span> <span class="o">=</span> <span class="n">TextModule</span><span class="p">(</span><span class="n">some_prompt_template</span><span class="p">)</span>  

<span class="c1"># OpenAI activation is also a Module so we can chain it explicitly here:</span>
<span class="n">task_module_w_CoT</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>  
    <span class="n">task</span><span class="p">,</span>  
    <span class="n">chain_of_thought</span><span class="p">,</span>
    <span class="n">OpenAI</span><span class="p">(</span><span class="s2">&quot;gpt-4&quot;</span><span class="p">)</span>
<span class="p">)</span>  
</code></pre></div>
<p>Or subclassing <code>TextModule</code> and overriding the forward method:
<div class="highlight"><pre><span></span><code><span class="c1"># Custom TextModule override methods like __init__ and forward</span>
<span class="k">class</span> <span class="nc">ChainOfThought</span><span class="p">(</span><span class="n">TextModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()(</span><span class="nb">input</span> <span class="o">+</span> <span class="s2">&quot; Let&#39;s think step by step.&quot;</span><span class="p">)</span>

<span class="c1"># By subclassing and using super() we can still set prompts and activations</span>
<span class="n">task</span> <span class="o">=</span> <span class="n">ChainOfThought</span><span class="p">(</span><span class="n">some_prompt_template</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">llm</span><span class="p">)</span>
</code></pre></div></p>
<h3 id="ensemble-self-consistency">Ensemble / Self-consistency</h3>
<p>Many benefits of being able to represent texts "geometrically" in a matrix / tensor comes from being able to create a meaningful structure, where e.g. a 2d matrix has columns representing different versions of the same text and subsequent entries represent subsequent paragraphs. Methods like ensemble voting and self-consistency require creating multiple completions for the same task, which can be representing by adding such a "version" dimension.</p>
<p>In this example, we will build such a module that for each entry creates multiple answer entries and combines them back together to increase the overall performance. First, to add a new dimension with different answers given by the LLM we need only adjust the <code>n</code> parameter. Additionally, we can set the system message:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">langtorch</span> <span class="kn">import</span> <span class="n">OpenAI</span>
<span class="n">ensemble_llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">,</span> 
                      <span class="n">system_message</span><span class="o">=</span><span class="s2">&quot;You are a rewriting bot that answers only with the revised text&quot;</span><span class="p">,</span> 
                      <span class="n">T</span><span class="o">=</span><span class="mf">1.1</span><span class="p">,</span> <span class="c1"># High temperature to sample diverse completions</span>
                      <span class="n">n</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span> <span class="c1"># 5 completions for each entry</span>
</code></pre></div>
<p>To use a concrete example, we will write a module that uses an ensemble to compress a text paragraph by paragraph. The task description is inspired by the Chain of Density method. For now, let's assume <code>paragraphs</code> is defined as a TextTensor with 15 paragraph-entries:</p>
<div class="highlight"><pre><span></span><code><span class="n">rewrite</span> <span class="o">=</span> <span class="n">TextModule</span><span class="p">([</span><span class="s2">&quot;Compress all information from the paragraph into an entity-dense telegraphic summary: &quot;</span><span class="p">],</span> <span class="n">activation</span> <span class="o">=</span> <span class="n">ensemble_llm</span><span class="p">)</span> 
<span class="n">ensemble_summaries</span> <span class="o">=</span> <span class="n">rewrite</span><span class="p">(</span><span class="n">paragraphs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ensemble_summaries</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1"># Outputs (15, 5)</span>
</code></pre></div>
<p>The last dimension now identifies different summaries. To combine them we could:</p>
<ul>
<li>Add a separator to each entry and use<code>.sum(dim=-1)</code>to create 15 entries with texts to combine and pass them to a "create a combined text" module </li>
<li>We can do this even quicker with langtorch's "<a href="../reference/langtorch">semantic algebra</a>", which has a <code>mean</code> function that creates a better "average" text from texts along a dimension.</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">combined_summaries</span> <span class="o">=</span> <span class="n">langtorch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ensemble_summaries</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">combined_summaries</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1"># Outputs: (15)</span>

<span class="c1"># We can even average again across paragraphs!</span>
<span class="n">summary</span> <span class="o">=</span> <span class="n">langtorch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">combined_summaries</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">summary</span><span class="p">)</span>
<span class="c1"># Outputs: The discussion surrounding GPT-3&#39;s capabilities emphasizes its performance in the Turing Test, its tendency to prioritize plausibility over truth, and the societal implications of truth-related challenges (...)</span>
</code></pre></div>
<p>Similar approaches can be used for more complicated ensemble methods or combined with methods like chain of thought to increase accuracy with "self-consistency".</p>
<h3 id="working-with-structured-documents">Working with structured documents</h3>
<p>Instead of strings, each entry of a TextTensor is an instance of <a href="reference/text"><code>langtorch.Text</code></a>, which allows for more complex text processing. The <code>Text</code> class can load documents, parse most markup languages and provide a helpful interface for accessing and modifying their structured text segments. We will prepare data for a rewrite task like before by parsing a markdown file of a paper on the abilities of language models, available here <a download="paper.md" href="../static/paper.txt">paper.md</a>. As the text has headers and other text blocks, we'll to select only paragraphs, which can be done with <code>iloc</code> and <code>loc</code> accessors:  </p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">langtorch</span> <span class="kn">import</span> <span class="n">Text</span>
<span class="n">paper</span> <span class="o">=</span> <span class="n">Text</span><span class="o">.</span><span class="n">from_file</span><span class="p">(</span><span class="s2">&quot;paper.md&quot;</span><span class="p">)</span>
<span class="c1"># Text automatically parses markdown, encoding its text block structure to let us simply access and modify their content</span>

<span class="c1"># To access the first block </span>
<span class="n">first_block</span> <span class="o">=</span> <span class="n">paper</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># To filter block types, we can take us that Text segments are have labels, accessible via:</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">paper</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
<span class="c1"># Outputs: {&#39;BlockQuote&#39;, &#39;Para&#39;, &#39;Header1&#39;, &#39;Header3&#39;, &#39;Header2&#39;}</span>

<span class="c1"># To get all paragraphs</span>
<span class="n">paragraphs</span> <span class="o">=</span> <span class="n">paper</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;Para&quot;</span><span class="p">]</span>

<span class="c1"># Some rewritting module</span>
<span class="n">rewritten_paragraphs</span> <span class="o">=</span> <span class="n">rewrite</span><span class="p">(</span><span class="n">paragraphs</span><span class="p">)</span>

<span class="c1"># We can easily edit the unfiltered text by setting rewritten paragraphs</span>
<span class="n">paper</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;Para&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">rewritten_paragraphs</span>
<span class="nb">print</span><span class="p">(</span><span class="n">paper</span><span class="p">)</span> <span class="c1"># Outputs a string of the paper formatted in markdown with all rewritten paragraphs in their original places </span>
</code></pre></div>
<h2 id="3-using-tensor-embeddings-to-build-retrievers">3. Using Tensor Embeddings to Build Retrievers</h2>
<p>Using embeddings with TextTensors is extremely easy, as every TextTensor can generate its own embedding, as well as know to automatically act as if it was an embedding tensor when passed to torch functions like cosine similarity. These representations (available under the <code>.embedding</code> attribute) are moreover automatically created only right before they are needed (via a set embedding model, by default OpenAI's <code>text-embedding-3-small</code>). </p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>  

<span class="n">tensor1</span> <span class="o">=</span> <span class="n">TextTensor</span><span class="p">([[[</span><span class="s2">&quot;Yes&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;No&quot;</span><span class="p">]]])</span>  
<span class="n">tensor2</span> <span class="o">=</span> <span class="n">TextTensor</span><span class="p">([</span><span class="s2">&quot;Yeah&quot;</span><span class="p">,</span> <span class="s2">&quot;Nope&quot;</span><span class="p">,</span> <span class="s2">&quot;Yup&quot;</span><span class="p">,</span> <span class="s2">&quot;Non&quot;</span><span class="p">])</span>  

<span class="n">torch</span><span class="o">.</span><span class="n">cosine_similarity</span><span class="p">(</span><span class="n">tensor1</span><span class="p">,</span><span class="n">tensor2</span><span class="p">)</span>
</code></pre></div>
<h3 id="build-custom-retriever-and-rag-modules">Build Custom Retriever and RAG modules</h3>
<p>Using how <code>TextTensor</code>s can automatically act as a<code>Tensor</code> of it's embeddings, we can very compactly implement e.g. a retriever, which for each entry in the input finds in parallel <code>k</code> entries with the highest cosine similarity among the documents it holds:</p>
<p><div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">Retriever</span><span class="p">(</span><span class="n">TextModule</span><span class="p">):</span>  
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">documents</span><span class="p">:</span> <span class="n">TextTensor</span><span class="p">):</span>  
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>  
        <span class="bp">self</span><span class="o">.</span><span class="n">documents</span> <span class="o">=</span> <span class="n">TextTensor</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>  

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">:</span> <span class="n">TextTensor</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">):</span>  
        <span class="n">cos_sim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cosine_similarity</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">documents</span><span class="p">,</span> <span class="n">query</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>  
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">documents</span><span class="p">[</span><span class="n">cos_sim</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">k</span><span class="p">)]</span>
</code></pre></div>
<div class="highlight"><span class="filename">Usage:</span><pre><span></span><code><span class="n">retriever</span> <span class="o">=</span> <span class="n">Retriever</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s2">&quot;doc.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">readlines</span><span class="p">())</span>
<span class="n">query</span> <span class="o">=</span> <span class="n">TextTensor</span><span class="p">(</span><span class="s2">&quot;How to build a retriever?&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">retriever</span><span class="p">(</span><span class="n">query</span><span class="p">))</span>
</code></pre></div></p>
<p>Note how the implementation didn't require us to learn about any new operations we would not find in regular PyTorch. One goal of LangTorch is to give developers control over these lower level operations, while being able to write compact code without a multitude of classes. For this reason implementations such as the retriever above are not pre-defined classes in the main package.  </p>
<p>We can now compose this module with a Module making LLM calls to get a custom Retrieval Augmented Generation pipeline:</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">RAG</span><span class="p">(</span><span class="n">TextModule</span><span class="p">):</span>  
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">documents</span><span class="p">:</span> <span class="n">TextTensor</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>  
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  
        <span class="bp">self</span><span class="o">.</span><span class="n">retriever</span> <span class="o">=</span> <span class="n">Retriever</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>  

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">user_message</span><span class="p">:</span> <span class="n">TextTensor</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">):</span>  
        <span class="n">retrieved_context</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">retriever</span><span class="p">(</span><span class="n">user_message</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span> <span class="o">+</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>  
        <span class="n">user_message</span> <span class="o">=</span> <span class="n">user_message</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">CONTEXT:</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="n">retrieved_context</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>  
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">user_message</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><span class="filename">Usage:</span><pre><span></span><code><span class="n">rag_chat</span> <span class="o">=</span> <span class="n">RAG</span><span class="p">(</span><span class="n">paragraphs</span><span class="p">,</span>  
               <span class="n">prompt</span><span class="o">=</span><span class="s2">&quot;Use the context to answer the following user query: &quot;</span><span class="p">,</span>
               <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">)</span>

<span class="n">assistant_response</span> <span class="o">=</span> <span class="n">rag_chat</span><span class="p">(</span><span class="n">user_query</span><span class="p">)</span>
</code></pre></div>
<p>With only small modifications to the retriever this module could also perform batched inference  performing multiple simultaneous queries without much additional latency. Note, <code>prompt</code> and <code>activation</code> are arguments inherited from TextModule and need the <code>super().forward</code> call to work. </p>
<p>We are excited to see what you will build with LangTorch. If you want to share some examples or have any questions, feel free to ask on our <a href="https://discord.gg/jkreqtCCkv">discord</a>. In the likely event of encountering a bug send it on discord or post on the <a href="https://github.com/AdamSobieszek/langtorch">GitHub Repo</a> and we will fix it ASAP.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["content.code.annotate", "content.code.copy", "navigation.indexes", "navigation.sections"], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.8fd75fb4.min.js"></script>
      
        <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"></script>
      
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      
        <script src="https://unpkg.com/tablesort@5.3.0/dist/tablesort.min.js"></script>
      
        <script src="../css/tabs.js"></script>
      
    
  </body>
</html>